{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "46243c064e7a43969d57eb60213c4521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf6a9eb085b54db98cb1a55b4580e7b2",
              "IPY_MODEL_1a9935b91ffb45428ef3f7851fd95125",
              "IPY_MODEL_121e7a7ea66b47a38b31cb8609d90fd9"
            ],
            "layout": "IPY_MODEL_afded515751047f7971880a4a36abf84"
          }
        },
        "bf6a9eb085b54db98cb1a55b4580e7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9a7bacc4004fd4bb82350366b946f1",
            "placeholder": "​",
            "style": "IPY_MODEL_dd40982586d54c8abac2e6b9f45a2316",
            "value": "Epoch 0:  17%"
          }
        },
        "1a9935b91ffb45428ef3f7851fd95125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c393a93b7fa4af0b75f5a2f7adec376",
            "max": 469,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a45f692a9422438bbad5004e9fb344ca",
            "value": 82
          }
        },
        "121e7a7ea66b47a38b31cb8609d90fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36cfec7c903456f82ab0b3f9126d042",
            "placeholder": "​",
            "style": "IPY_MODEL_72b6886c8249407f80ec32c7b43b1136",
            "value": " 82/469 [00:03&lt;00:16, 24.15it/s, v_num=2]"
          }
        },
        "afded515751047f7971880a4a36abf84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "6e9a7bacc4004fd4bb82350366b946f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd40982586d54c8abac2e6b9f45a2316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c393a93b7fa4af0b75f5a2f7adec376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a45f692a9422438bbad5004e9fb344ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f36cfec7c903456f82ab0b3f9126d042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b6886c8249407f80ec32c7b43b1136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\" width=\"100%\">\n",
        "    <img width=\"66%\" src=\"https://raw.githubusercontent.com/linukc/master_dlcourse/main/images/logo.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "DxaHRUL5LQCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **[MIPT DL frameworks Spring 2024](https://wiki.cogmodel.mipt.ru/s/mtai/doc/2024-nejrosetevye-frejmvorki-glubokogo-obucheniya-ZBGd69bxLd). Class 2: Training on different platforms**"
      ],
      "metadata": {
        "id": "ym0WWFVJ7IYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch"
      ],
      "metadata": {
        "id": "5rYdPZaVmEf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "Hf2p7EWOmKqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "LUiOaAuNmNkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}, {X.dtype}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5owk4i0GmNm3",
        "outputId": "97d17b39-7ed8-481f-a83f-46d6d406f671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([128, 1, 28, 28]), torch.float32\n",
            "Shape of y: torch.Size([128]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 64)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "5qj9HI-2-E6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU / GPU"
      ],
      "metadata": {
        "id": "YlLxFqYu4BSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh1i4N8H4iDU",
        "outputId": "49fe64d1-42c2-4579-b597-4672b7bb5ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "QmFFjkMVmNqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "QnQRm0LG-U0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = torch.compile(model)"
      ],
      "metadata": {
        "id": "gZ7dulwtu2UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28m5RSOh1tA1",
        "outputId": "fa2822f8-5560-4336-928c-44976806dc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 837 µs (started: 2024-02-19 00:58:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRg5vXa31u12",
        "outputId": "5996e16d-779b-4e23-b952-39b14f4b22c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 516 µs (started: 2024-02-19 00:58:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r82qfd7T1yUu",
        "outputId": "ed1fd432-1f3f-4e35-9cf0-9a735e810f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4.161592  [   64/60000]\n",
            "loss: 4.118782  [ 6464/60000]\n",
            "loss: 4.108646  [12864/60000]\n",
            "loss: 4.032907  [19264/60000]\n",
            "loss: 4.016744  [25664/60000]\n",
            "loss: 3.971307  [32064/60000]\n",
            "loss: 3.931408  [38464/60000]\n",
            "loss: 3.884785  [44864/60000]\n",
            "loss: 3.714263  [51264/60000]\n",
            "loss: 3.658295  [57664/60000]\n",
            "Done!\n",
            "time: 11.3 s (started: 2024-02-19 00:58:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfdqLiU_2Opv",
        "outputId": "16b42f7d-e7fa-464b-ba86-bc2fdf87481c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n",
            "time: 8.12 ms (started: 2024-02-19 00:58:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nZMs04D2CTC",
        "outputId": "57e75d44-8922-4df8-c0c1-306d0aea34f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 14.9 ms (started: 2024-02-19 00:58:36 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultiGPU (DDP)"
      ],
      "metadata": {
        "id": "VNZWk1RLG2Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile train.py\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import torch.multiprocessing as mp\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "import os\n",
        "\n",
        "\n",
        "def ddp_setup(rank, world_size):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        rank: Unique identifier of each process\n",
        "        world_size: Total number of processes\n",
        "    \"\"\"\n",
        "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
        "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
        "    torch.cuda.set_device(rank)\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: torch.nn.Module,\n",
        "        train_data: DataLoader,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        gpu_id: int,\n",
        "        save_every: int,\n",
        "    ) -> None:\n",
        "        self.gpu_id = gpu_id\n",
        "        self.model = model.to(gpu_id)\n",
        "        self.train_data = train_data\n",
        "        self.optimizer = optimizer\n",
        "        self.save_every = save_every\n",
        "        self.model = DDP(model, device_ids=[gpu_id])\n",
        "\n",
        "    def _run_batch(self, source, targets):\n",
        "        self.optimizer.zero_grad()\n",
        "        output = self.model(source.view(-1, 28*28))\n",
        "        loss = F.cross_entropy(output, targets)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def _run_epoch(self, epoch):\n",
        "        b_sz = len(next(iter(self.train_data))[0])\n",
        "        print(f\"[GPU{self.gpu_id}] Epoch {epoch} | Batchsize: {b_sz} | Steps: {len(self.train_data)}\")\n",
        "        self.train_data.sampler.set_epoch(epoch)\n",
        "        for source, targets in self.train_data:\n",
        "            source = source.to(self.gpu_id)\n",
        "            targets = targets.to(self.gpu_id)\n",
        "            self._run_batch(source, targets)\n",
        "\n",
        "    def _save_checkpoint(self, epoch):\n",
        "        ckp = self.model.module.state_dict()\n",
        "        PATH = \"checkpoint.pt\"\n",
        "        torch.save(ckp, PATH)\n",
        "        print(f\"Epoch {epoch} | Training checkpoint saved at {PATH}\")\n",
        "\n",
        "    def train(self, max_epochs: int):\n",
        "        for epoch in range(max_epochs):\n",
        "            self._run_epoch(epoch)\n",
        "            if self.gpu_id == 0 and epoch % self.save_every == 0:\n",
        "                self._save_checkpoint(epoch)\n",
        "\n",
        "\n",
        "def load_train_objs():\n",
        "    train_set = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    )\n",
        "    model = torch.nn.Linear(28 * 28, 64)  # load your model\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "    return train_set, model, optimizer\n",
        "\n",
        "\n",
        "def prepare_dataloader(dataset: Dataset, batch_size: int):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        pin_memory=True,\n",
        "        shuffle=False,\n",
        "        sampler=DistributedSampler(dataset)\n",
        "    )\n",
        "\n",
        "\n",
        "def main(rank: int, world_size: int, save_every: int, total_epochs: int, batch_size: int):\n",
        "    ddp_setup(rank, world_size)\n",
        "    dataset, model, optimizer = load_train_objs()\n",
        "    train_data = prepare_dataloader(dataset, batch_size)\n",
        "    trainer = Trainer(model, train_data, optimizer, rank, save_every)\n",
        "    trainer.train(total_epochs)\n",
        "    destroy_process_group()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    world_size = torch.cuda.device_count()\n",
        "    mp.spawn(main, args=(world_size, 2, 10, 32), nprocs=world_size)"
      ],
      "metadata": {
        "id": "Uv9R8b_gG9m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py"
      ],
      "metadata": {
        "id": "QlouQ2zHSWHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TPU"
      ],
      "metadata": {
        "id": "eoCQnF8S4E0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A TPU is a Tensor processing unit. Each TPU has 8 cores where each core is optimized for 128x128 matrix multiplies. In general, a single TPU is about as fast as 5 V100 GPUs!"
      ],
      "metadata": {
        "id": "aFS5QNJ0TgN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Detect if a TPU is available and initialize it\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        "  print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
        "except ValueError:\n",
        "  print(\"Not connected to a TPU runtime. Using CPU/GPU strategy\")\n",
        "  strategy = tf.distribute.get_strategy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRqNWa2N9Jc_",
        "outputId": "6c51b726-3bc0-47ab-f371-59eb77da3581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.68.97.34:8470']\n",
            "Number of replicas: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3vM8ASfCieZ",
        "outputId": "79c49ea8-926c-4470-f5c9-43b042ae56af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                            2.1.0+cu121\n",
            "torchaudio                       2.1.0+cu121\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch_xla==2.1.0 https://storage.googleapis.com/pytorch-xla-releases/wheels/xrt/tpuvm/torch_xla-2.1.0%2Bxrt-cp310-cp310-manylinux_2_28_x86_64.whl"
      ],
      "metadata": {
        "id": "fiuYCDXO40Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single XLA device"
      ],
      "metadata": {
        "id": "eLGGOBwPECIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "oc8_YNZK9xYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = xm.xla_device()\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc6MOX2mDqaj",
        "outputId": "5010eefe-f528-401f-bb01-774951c308f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='xla', index=1)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "LgLx65l1ESty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        xm.mark_step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    print(f\"batch {batch}: loss {loss.item()}\")"
      ],
      "metadata": {
        "id": "7dgYQOT1C01U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHI8LjmvEvXR",
        "outputId": "cfb116c5-31f8-42eb-f06b-146b8bcd99af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 4.158014  [  128/60000]\n",
            "loss: 4.127364  [12928/60000]\n",
            "loss: 4.096592  [25728/60000]\n",
            "loss: 4.060153  [38528/60000]\n",
            "loss: 4.009383  [51328/60000]\n",
            "batch 468: loss 4.006476402282715\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple XLA Devices with Multi-processing"
      ],
      "metadata": {
        "id": "sYkofMIuF2B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%writefile train.py\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 64)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "#API to minimize the use of host memory with the `spawn(..., start_method='fork')\n",
        "WRAPPED_MODEL = xmp.MpModelWrapper(NeuralNetwork())\n",
        "SERIAL_EXEC = xmp.MpSerialExecutor() #Avoid all cores downloading the same data\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer, device):\n",
        "  size = len(dataloader.dataset)\n",
        "  mp_device_loader = pl.MpDeviceLoader(dataloader, device)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(mp_device_loader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    xm.optimizer_step(optimizer)\n",
        "\n",
        "  loss = loss.item()\n",
        "  print(f\"batch {batch}, loss: {loss:>7f}\")\n",
        "\n",
        "def _mp_fn(index):\n",
        "  def get_data():\n",
        "    return datasets.MNIST(\n",
        "              root=\"data\",\n",
        "              train=True,\n",
        "              download=True,\n",
        "              transform=ToTensor())\n",
        "\n",
        "  print(xm.xrt_world_size(), xm.get_ordinal())\n",
        "  train_dataset = SERIAL_EXEC.run(get_data)\n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    train_dataset,\n",
        "    num_replicas=xm.xrt_world_size(),\n",
        "    rank=xm.get_ordinal(),\n",
        "    shuffle=True)\n",
        "\n",
        "  device = xm.xla_device()\n",
        "  model = WRAPPED_MODEL.to(device)\n",
        "  train_dataloader = DataLoader(train_dataset, batch_size=8*128, sampler=train_sampler)\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=8*1e-3)\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  epochs = 1\n",
        "  for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer, device)\n",
        "    print(\"Done!\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  xmp.spawn(_mp_fn, args=(), nprocs=8, start_method='fork')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCBxLG-TGEO0",
        "outputId": "99ecf60b-b2d0-4c90-eacb-477c2e7d1652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeudEPJRKc40",
        "outputId": "1ff67141-2790-4b0b-846a-d55457a09ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 0\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "8 3\n",
            "8 1\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "8 7\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "8 5\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "8 6\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "8 4\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "8 2\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "batch 7, loss: 4.141041\n",
            "Done!\n",
            "batch 7, loss: 4.147089\n",
            "batch 7, loss: 4.142928\n",
            "batch 7, loss: 4.145471\n",
            "Done!\n",
            "Done!\n",
            "batch 7, loss: 4.145340\n",
            "batch 7, loss: 4.147279\n",
            "Done!\n",
            "Done!\n",
            "batch 7, loss: 4.145200\n",
            "Done!\n",
            "Done!\n",
            "batch 7, loss: 4.139385\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/pytorch/xla/blob/master/test/test_train_mp_mnist.py"
      ],
      "metadata": {
        "id": "RIhdFipetEep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Lightning"
      ],
      "metadata": {
        "id": "yR1sO0_h3YcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m pip install lightning==2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyytZBcyUhz7",
        "outputId": "7e506954-6940-4c50-d543-f3b780ea9415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning==2.1\n",
            "  Downloading lightning-2.1.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1) (2023.6.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning==2.1)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1) (1.25.2)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1) (23.2)\n",
            "Requirement already satisfied: torch<4.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1) (2.1.0+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning==2.1)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning==2.1) (4.9.0)\n",
            "Collecting pytorch-lightning (from lightning==2.1)\n",
            "  Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning==2.1) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.1) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.1) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.12.0->lightning==2.1) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.12.0->lightning==2.1) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning==2.1) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.12.0->lightning==2.1) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.1.0 lightning-utilities-0.10.1 pytorch-lightning-2.2.0.post0 torchmetrics-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Computational code goes into LightningModule\n",
        "2. Set forward hook\n",
        "3. Set optimizers hook\n",
        "4. Set train_step hook\n",
        "5. Set validation hook\n",
        "6. Remove any device calls\n",
        "7. Override hooks as needed\n",
        "8. Init Lightning Module\n",
        "9. Init Trainer\n",
        "10. Pass Dataloader\n",
        "11. .fit()\n"
      ],
      "metadata": {
        "id": "2fpO849ewR33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "uY54uQPzv5jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 64)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "fgc9OAzrz7-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModule(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = NeuralNetwork()\n",
        "        self.loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # in lightning, forward defines the prediction/inference actions\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # training_step defined the train loop.\n",
        "        # It is independent of forward\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.loss_func(out, y)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "        return optimizer"
      ],
      "metadata": {
        "id": "OEQoN5AwwBWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor(),\n",
        ")\n",
        "\n",
        "batch_size = 128\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "MGyjhToCyFXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init model\n",
        "model = MnistModule()\n",
        "\n",
        "# most basic trainer, uses good defaults (auto-tensorboard, checkpoints, logs, and more)\n",
        "trainer = pl.Trainer()\n",
        "#trainer = pl.Trainer(accelerator=\"gpu\", devices=1)\n",
        "#trainer = pl.Trainer(accelerator=\"tpu\", devices=[1])\n",
        "#trainer = pl.Trainer(accelerator=\"tpu\", devices=8)\n",
        "trainer.fit(model, train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "46243c064e7a43969d57eb60213c4521",
            "bf6a9eb085b54db98cb1a55b4580e7b2",
            "1a9935b91ffb45428ef3f7851fd95125",
            "121e7a7ea66b47a38b31cb8609d90fd9",
            "afded515751047f7971880a4a36abf84",
            "6e9a7bacc4004fd4bb82350366b946f1",
            "dd40982586d54c8abac2e6b9f45a2316",
            "7c393a93b7fa4af0b75f5a2f7adec376",
            "a45f692a9422438bbad5004e9fb344ca",
            "f36cfec7c903456f82ab0b3f9126d042",
            "72b6886c8249407f80ec32c7b43b1136"
          ]
        },
        "id": "YREczYejyIz8",
        "outputId": "b7c44635-ca00-4ec4-b3d0-3eb2a014161b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name      | Type             | Params\n",
            "-----------------------------------------------\n",
            "0 | model     | NeuralNetwork    | 697 K \n",
            "1 | loss_func | CrossEntropyLoss | 0     \n",
            "-----------------------------------------------\n",
            "697 K     Trainable params\n",
            "0         Non-trainable params\n",
            "697 K     Total params\n",
            "2.790     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46243c064e7a43969d57eb60213c4521"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}